/**
 * LLM Routing and Fallback Systems Test
 */
import LocalLLMManager from './claude-brain/LocalLLMManager';
import SevenModelManager from './claude-brain/SevenModelManager';

async function testLLMRouting() {
  try {
    console.log('ğŸ§  LLM Routing Test: Loading components...');
    
    // Test Model Manager
    console.log('ğŸ”§ Testing Seven Model Manager...');
    const modelManager = new SevenModelManager();
    console.log('âœ… Seven Model Manager: Loaded');
    
    // Test Local LLM Manager
    console.log('ğŸ”§ Testing Local LLM Manager...');
    const localLLM = new LocalLLMManager();
    const status = localLLM.getStatus();
    console.log('ğŸ“Š Local LLM Status:', status);
    
    // Check for Ollama availability
    console.log('ğŸ” Checking Ollama server...');
    const { execSync } = require('child_process');
    try {
      const processes = execSync('pgrep -f "ollama serve" || echo "none"', { encoding: 'utf8' }).trim();
      if (processes === 'none' || !processes) {
        console.log('â„¹ï¸ Ollama server not detected - fallback mode');
      } else {
        console.log('âœ… Ollama server detected');
        const modelList = execSync('ollama list', { encoding: 'utf8' });
        const lines = modelList.split('\n').filter(line => line.trim() && !line.includes('NAME'));
        console.log(`ğŸ“Š Available models: ${lines.length}`);
      }
    } catch (err) {
      console.log('â„¹ï¸ Ollama not available - using fallback routing');
    }
    
    console.log('ğŸ§  LLM Routing Test: PASS');
    return true;
  } catch (error) {
    console.error('âŒ LLM Routing Test: FAIL', error.message);
    return false;
  }
}

testLLMRouting();